{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda install -y mkl > tmp.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from lasagne.utils import floatX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Zoo\n",
    "* https://github.com/Lasagne/Recipes/tree/master/modelzoo\n",
    "* More models within the community\n",
    "* Pick model, copy init, download weights\n",
    "* Here we proceed with vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg16.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copyright: see http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "\n",
    "\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    net['conv1_1'] = ConvLayer(\n",
    "        net['input'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['conv1_2'] = ConvLayer(\n",
    "        net['conv1_1'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(\n",
    "        net['pool1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['conv2_2'] = ConvLayer(\n",
    "        net['conv2_1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(\n",
    "        net['pool2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_2'] = ConvLayer(\n",
    "        net['conv3_1'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_3'] = ConvLayer(\n",
    "        net['conv3_2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['pool3'] = PoolLayer(net['conv3_3'], 2)\n",
    "    net['conv4_1'] = ConvLayer(\n",
    "        net['pool3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_2'] = ConvLayer(\n",
    "        net['conv4_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_3'] = ConvLayer(\n",
    "        net['conv4_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool4'] = PoolLayer(net['conv4_3'], 2)\n",
    "    net['conv5_1'] = ConvLayer(\n",
    "        net['pool4'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_2'] = ConvLayer(\n",
    "        net['conv5_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_3'] = ConvLayer(\n",
    "        net['conv5_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool5'] = PoolLayer(net['conv5_3'], 2)\n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "    net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=4096)\n",
    "    net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "    net['fc8'] = DenseLayer(\n",
    "        net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ostrich, Struthio camelus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('classes.txt') as f:\n",
    "    classes = f.readlines()\n",
    "    \n",
    "classes = [x.strip() for x in classes]\n",
    "print(classes[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to implement two functions in the cell below.\n",
    "\n",
    "Preprocess function should take the image with shape (w, h, 3) and transform it into a tensor with shape (1, 3, 224, 224). Without this transformation, vgg19 won't be able to digest input image. \n",
    "Additionally, your preprocessing function have to rearrange channels RGB -> BGR and subtract mean values from every channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123])\n",
    "IMAGE_W = 224\n",
    "\n",
    "def preprocess(img):\n",
    "    img = img.copy().astype(np.float32)\n",
    "    img = img - MEAN_VALUES\n",
    "    img = img[:,:,::-1]\n",
    "    \n",
    "    #convert from [w,h,3 to 1,3,w,h]\n",
    "    img = np.transpose(img, (2, 0, 1))[None]\n",
    "    return img\n",
    "\n",
    "def deprocess(img):\n",
    "    img = img.copy().astype(np.float32)\n",
    "    img = img.reshape(img.shape[1:]).transpose((1, 2, 0))\n",
    "    for i in range(3):\n",
    "        img[:,:, i] += MEAN_VALUES[-1-i]\n",
    "    return img[:, :, :: -1].astype(np.uint8)\n",
    "\n",
    "img = (np.random.rand(IMAGE_W, IMAGE_W, 3) * 256).astype(np.uint8)\n",
    "\n",
    "print (np.linalg.norm(deprocess(preprocess(img)) - img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, the number above will be small, because deprocess function is the inverse of preprocess function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('vgg16.pkl', 'rb') as f:\n",
    "    weights = pickle.load(f, encoding = 'latin1')\n",
    "\n",
    "lasagne.layers.set_all_param_values(net['prob'], weights['param values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = T.tensor4('input')\n",
    "output = lasagne.layers.get_output(net['prob'], input_image)\n",
    "prob = theano.function([input_image], output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "Давайте проверим, что загруженная сеть работает. Для этого мы скормим ей картину альбатроса и проверим, что она правильно его распознаёт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = imread('sample_images/albatross.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "p = prob(preprocess(img))\n",
    "\n",
    "labels = p.ravel().argsort()[-1:-6:-1]\n",
    "print 'top-5 classes are:'\n",
    "for l in labels:\n",
    "    print '%3f\\t%s' % (p.ravel()[l], classes[l].split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand-quest: Dogs Vs Cats\n",
    "* original competition\n",
    "* https://www.kaggle.com/c/dogs-vs-cats\n",
    "* 25k JPEG images of various size, 2 classes (guess what)\n",
    "\n",
    "### Your main objective\n",
    "* In this seminar your goal is to fine-tune a pre-trained model to distinguish between the two rivaling animals\n",
    "* The first step is to just reuse some network layer as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/d61lupw909hc785/dogs_vs_cats.train.zip?dl=1 -O data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for starters\n",
    "* Train sklearn model, evaluate validation accuracy (should be >80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract features from images\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imresize\n",
    "import os\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "#this may be a tedious process. If so, store the results in some pickle and re-use them.\n",
    "for fname in tqdm(os.listdir('train/')):\n",
    "    y = fname.startswith(\"cat\")\n",
    "    img = imread(\"train/\"+fname)\n",
    "    img = preprocess(imresize(img,(IMAGE_W,IMAGE_W)))\n",
    "    features = <preprocess the image into features)\n",
    "    Y.append(y)\n",
    "    X.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 4096)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('X_file.npy')\n",
    "Y = np.load('y_file.npy')\n",
    "\n",
    "X = np.asarray(X) #stack all [1xfeature] matrices into one. \n",
    "assert X.ndim==2\n",
    "#WARNING! the concatenate works for [1xN] matrices. If you have other format, stack them yourself.\n",
    "\n",
    "#crop if we ended prematurely\n",
    "Y = Y[:len(X)]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "     X, Y, test_size=0.1, random_state=42)\n",
    "#test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_train, y_train, test_size=0.1111, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load our dakka__\n",
    "![img](https://s-media-cache-ak0.pinimg.com/564x/80/a1/81/80a1817a928744a934a7d32e7c03b242.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Main quest\n",
    "\n",
    "* Get the score improved!\n",
    "\n",
    "No methods are illegal: ensembling, data augmentation, NN hacks. \n",
    "Just don't let test data slip into training.\n",
    "\n",
    "The main requirement is that you implement the NN fine-tuning recipe:\n",
    "### Split the raw image data\n",
    "  * please do train/validation/test instead of just train/test\n",
    "  * reasonable but not optimal split is 20k/2.5k/2.5k or 15k/5k/5k\n",
    "### Choose which vgg layers are you going to use\n",
    "  * Anything but for prob is okay\n",
    "  * Do not forget that vgg16 uses dropout\n",
    "### Build a few layers on top of chosen \"neck\" layers.\n",
    "  * a good idea is to just stack more layers inside the same network\n",
    "  * alternative: stack on top of get_output\n",
    "### Train the newly added layers for some iterations\n",
    "  * you can selectively train some weights by only sending them to your optimizer\n",
    "      * `lasagne.updates.mysupermegaoptimizer(loss, only_those_weights_i_wanna_train)`\n",
    "  * selecting all weights from the head but not below the neck:\n",
    "      * `all_params = lasagne.layers.get_all_params(new_output_layer_or_layers,trainable=True)`\n",
    "      * `old_params= lasagne.layers.get_all_params(neck_layers,trainable=True)`\n",
    "      * `new_params = [w for w in all_params if w not in old_params]`\n",
    "  * it's cruicial to monitor the network performance at this and following steps\n",
    "### Fine-tune the network body\n",
    "  * probably a good idea to SAVE your new network weights now 'cuz it's easy to mess things up.\n",
    "  * Moreover, saving weights periodically is a no-nonsense idea\n",
    "  * even more cruicial to monitor validation performance\n",
    "  * main network body may need a separate, much lower learning rate\n",
    "      * since updates are dictionaries, one can just compute union\n",
    "      * `updates = {}`\n",
    "      * `updates.update(lasagne.updates.how_i_optimize_old_weights())`\n",
    "      * `updates.update(lasagne.updates.how_i_optimize_old_weights())`\n",
    "      * make sure they do not have overlapping keys. Otherwise, earlier one will be forgotten.\n",
    "      * `assert len(updates) == len(old_updates) + len(new_updates)`\n",
    "### PROFIT!!!\n",
    "  * Evaluate the final score\n",
    "  * Submit to kaggle\n",
    "      * competition page https://www.kaggle.com/c/dogs-vs-cats\n",
    "      * get test data https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "  \n",
    "## Some ways to get bonus points\n",
    "* explore other networks from the model zoo\n",
    "* play with architecture\n",
    "* 85%/90%/93%/95%/97% kaggle score (screen pls).\n",
    "* data augmentation, prediction-time data augmentation\n",
    "* use any more advanced fine-tuning technique you know/read anywhere\n",
    "* ml hacks that benefit the final score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can do it!\n"
     ]
    }
   ],
   "source": [
    "print (\"I can do it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predicted,true):\n",
    "    return 100*sum([(p==t) for p,t in zip(predicted,true)])/len(true)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation 97.32\n",
      "test 97.92\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train,y_train)\n",
    "predict_valid = random_forest.predict(X_valid)\n",
    "print('validation',accuracy(predict_valid,y_valid))\n",
    "predict_test = random_forest.predict(X_test)\n",
    "print('test',accuracy(predict_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation 97.8\n",
      "test 98.28\n"
     ]
    }
   ],
   "source": [
    "# Ridge Classifier\n",
    "ridge_classifier =  RidgeClassifier(alpha = 0.01)\n",
    "ridge_classifier.fit(X_train,y_train)\n",
    "predict_valid = ridge_classifier.predict(X_valid)\n",
    "print('validation',accuracy(predict_valid,y_valid))\n",
    "predict_test = ridge_classifier.predict(X_test)\n",
    "print('test',accuracy(predict_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validaion 98.4\n",
      "test 98.84\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logistic_regression =  LogisticRegression()\n",
    "logistic_regression.fit(X_train,y_train)\n",
    "predict_valid = logistic_regression.predict(X_valid)\n",
    "print('validaion',accuracy(predict_valid,y_valid))\n",
    "predict_test = logistic_regression.predict(X_test)\n",
    "print('test',accuracy(predict_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation 97.08\n",
      "test 98.4\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "ada_boosting_classifier =  AdaBoostClassifier()\n",
    "ada_boosting_classifier.fit(X_train,y_train)\n",
    "predict_valid = ada_boosting_classifier.predict(X_valid)\n",
    "print('validation',accuracy(predict_valid,y_valid))\n",
    "predict_test = ada_boosting_classifier.predict(X_test)\n",
    "print('test',accuracy(predict_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVC\n",
    "svc =  SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "predict_valid = svc.predict(X_valid)\n",
    "print('validation',accuracy(predict_valid,y_valid))\n",
    "predict_test = svc.predict(X_test)\n",
    "print('test',accuracy(predict_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "decision_tree_classifier =  DecisionTreeClassifier()\n",
    "decision_tree_classifier.fit(X_train,y_train)\n",
    "predict_valid = decision_tree_classifier.predict(X_valid)\n",
    "print('validation',accuracy(predict_valid,y_valid))\n",
    "predict_test = decision_tree_classifier.predict(X_test)\n",
    "print('test',accuracy(predict_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
